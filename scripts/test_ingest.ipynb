{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c79c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02468c-174b-4466-9631-11a88a841775",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Manush/Documents/PythonCode/job_agent_project/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from job_agent.discover.companies import get_company_list\n",
    "from job_agent.ingest.greenhouse import fetch_jobs\n",
    "from job_agent.ingest.parser import parse_greenhouse_job\n",
    "from job_agent.memory.store import JobStore\n",
    "from job_agent.models.profile import UserProfile\n",
    "from job_agent.rank.rules import passes_rules\n",
    "from job_agent.rank.text import job_text, profile_query\n",
    "from job_agent.rank.lexical import LexicalScorer\n",
    "from job_agent.rank.semantic import SemanticScorer\n",
    "from job_agent.enrich.fetch import fetch_job_page\n",
    "from job_agent.enrich.extract import extract_job_text\n",
    "from job_agent.memory.store import JobStore\n",
    "from job_agent.generate.cover_letter import generate_cover_letter_local, generate_cover_letter_gpt\n",
    "from job_agent.generate.local_llm import LocalLLM\n",
    "from job_agent.generate.resume import parse_resume_pdf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import sklearn\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b73901",
   "metadata": {},
   "source": [
    "## Fetching and Storing new Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a170fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/adobe/jobs\n",
      "[ingest] no Greenhouse board found for 'adobe', skipping\n",
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/airbnb/jobs\n",
      "[ingest] 200 jobs found for 'airbnb'\n",
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/databricks/jobs\n",
      "[ingest] 666 jobs found for 'databricks'\n",
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/google/jobs\n",
      "[ingest] no Greenhouse board found for 'google', skipping\n",
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/meta/jobs\n",
      "[ingest] no Greenhouse board found for 'meta', skipping\n",
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/spotify/jobs\n",
      "[ingest] no Greenhouse board found for 'spotify', skipping\n",
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/stripe/jobs\n",
      "[ingest] 519 jobs found for 'stripe'\n",
      "[ingest] fetching jobs from https://boards-api.greenhouse.io/v1/boards/uber/jobs\n",
      "[ingest] no Greenhouse board found for 'uber', skipping\n"
     ]
    }
   ],
   "source": [
    "store = JobStore(\"job_agent/data/jobs.db\")\n",
    "\n",
    "user_companies = [\"airbnb\", \"spotify\", \"adobe\"]  \n",
    "companies = get_company_list(user_companies)\n",
    "\n",
    "for company in companies:\n",
    "    raw_jobs = fetch_jobs(company)\n",
    "    if not raw_jobs:\n",
    "        continue\n",
    "\n",
    "    parsed_jobs = [parse_greenhouse_job(j, company) for j in raw_jobs]\n",
    "    store.save_jobs(parsed_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e890fdb-5e3c-4e61-b23f-b30530cae3fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobPosting(job_id='7374078', company='stripe', title='Account Executive, AI Sales', location='SF', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7374078', posted_date=datetime.date(2025, 12, 16), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7374073', company='stripe', title='Account Executive, AI Sales', location='SF', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7374073', posted_date=datetime.date(2025, 12, 16), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7403230', company='stripe', title='Account Executive, Benelux & Nordics - Existing Business', location='Dublin', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7403230', posted_date=datetime.date(2025, 12, 16), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7423968', company='stripe', title='Account Executive, Benelux - Startups (Dutch Speaking)', location='Amsterdam', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7423968', posted_date=datetime.date(2025, 12, 16), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7429465', company='stripe', title='Account Executive, CEE', location='Dublin', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7429465', posted_date=datetime.date(2025, 12, 16), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7343686', company='stripe', title='Account Executive, Commercial - DACH', location='Berlin', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7343686', posted_date=datetime.date(2025, 12, 16), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7306915', company='stripe', title='Account Executive, Commercial (Existing Business)', location='Chicago, IL.', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7306915', posted_date=datetime.date(2025, 12, 22), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7343682', company='stripe', title='Account Executive, Commercial - German Speaking', location='Dublin', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7343682', posted_date=datetime.date(2025, 12, 16), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7410669', company='stripe', title='Account Executive, Commercial - New Business', location='Dublin, London', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7410669', posted_date=datetime.date(2025, 12, 17), source='greenhouse')\n",
      "------------------------------------------------------------\n",
      "JobPosting(job_id='7368883', company='stripe', title='Account Executive, Commercial (New Business)', location='Chicago', description='', apply_url='https://stripe.com/jobs/search?gh_jid=7368883', posted_date=datetime.date(2025, 12, 22), source='greenhouse')\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for job in parsed_jobs[:10]:\n",
    "    print(job)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690e802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 0 new jobs\n",
      "Total jobs in DB: 1392\n"
     ]
    }
   ],
   "source": [
    "new_count = store.save_jobs(parsed_jobs)\n",
    "print(f\"Inserted {new_count} new jobs\")\n",
    "\n",
    "all_jobs = store.load_all_jobs()\n",
    "print(f\"Total jobs in DB: {len(all_jobs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d040d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = UserProfile(\n",
    "    target_roles=[\"ml engineer\", \"data scientist\", \"data engineer\"],\n",
    "    core_skills=[\n",
    "        \"machine learning\", \"deep learning\",\n",
    "        \"evaluation\", \"pytorch\", \"statistics\"\n",
    "    ],\n",
    "    location=[\"US\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ded72",
   "metadata": {},
   "source": [
    "## Hard Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db155120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31254, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../uscities.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afba33d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs before hard rules: 1392\n",
      "Jobs after hard rules: 250\n"
     ]
    }
   ],
   "source": [
    "filtered_jobs = [\n",
    "    job for job in all_jobs\n",
    "    if passes_rules(job, profile)\n",
    "]\n",
    "\n",
    "print(f\"Jobs before hard rules: {len(all_jobs)}\")\n",
    "print(f\"Jobs after hard rules: {len(filtered_jobs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80030d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_texts = [job_text(j) for j in filtered_jobs]\n",
    "job_ids = [j.job_id for j in filtered_jobs]\n",
    "query_text = profile_query(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e15fe",
   "metadata": {},
   "source": [
    "## Lexical and Semantic Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8d49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = LexicalScorer()\n",
    "lex.fit(job_texts, job_ids)\n",
    "lex_scores = lex.score_query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2344604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = SemanticScorer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "query_emb = sem.embed([query_text])[0]\n",
    "job_embs = sem.embed(job_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f65901",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for job, emb in zip(filtered_jobs, job_embs):\n",
    "    s_sem = sem.similarity(query_emb, emb)\n",
    "    s_lex = lex_scores.get(job.job_id, 0.0)\n",
    "    \n",
    "    rows.append({\n",
    "        \"job\": job,\n",
    "        \"semantic\": s_sem,\n",
    "        \"lexical\": s_lex,\n",
    "        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda9315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 10 BY SEMANTIC SIMILARITY ===\n",
      "\n",
      "sem=0.407\n",
      "Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.401\n",
      "Staff Machine Learning Engineer - Community Support Engineering @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.359\n",
      "Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.353\n",
      "Senior Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.333\n",
      "Senior Software Engineer - Fullstack (NYC) @ databricks\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.328\n",
      "Manager, Field Engineering (Pre-Sales) @ databricks\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.309\n",
      "Director, Engineering - Databricks Mosaic AI @ databricks\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.308\n",
      "Senior Solutions Engineer @ databricks\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.269\n",
      "Solutions Architect - Finland @ databricks\n",
      "--------------------------------------------------------------------------------\n",
      "sem=0.265\n",
      "Sr. Solutions Engineer, Retail - CPG @ databricks\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "top_semantic = sorted(\n",
    "    rows,\n",
    "    key=lambda r: r[\"semantic\"],\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "print(\"\\n=== TOP 10 BY SEMANTIC SIMILARITY ===\\n\")\n",
    "\n",
    "for r in top_semantic:\n",
    "    job = r[\"job\"]\n",
    "    print(f\"sem={r['semantic']:.3f}\")\n",
    "    print(f\"{job.title} @ {job.company}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357a8cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 10 BY LEXICAL MATCH ===\n",
      "\n",
      "lex=0.422\n",
      "Staff Machine Learning Engineer - Community Support Engineering @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.407\n",
      "Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.369\n",
      "Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.356\n",
      "Senior Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.339\n",
      "Senior Machine Learning Engineer, Stripe Assistant @ stripe\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.268\n",
      "Senior Data Scientist - Inference, Global Markets @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.206\n",
      "Staff Software Engineer, Experimentation Data @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.167\n",
      "Staff Software Engineer, Community Support Engineering @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.161\n",
      "Staff Software Engineer, Data Warehouse Compute @ airbnb\n",
      "--------------------------------------------------------------------------------\n",
      "lex=0.160\n",
      "Senior Staff Software Engineer, Community Support Engineering @ airbnb\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "top_lexical = sorted(\n",
    "    rows,\n",
    "    key=lambda r: r[\"lexical\"],\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "print(\"\\n=== TOP 10 BY LEXICAL MATCH ===\\n\")\n",
    "\n",
    "for r in top_lexical:\n",
    "    job = r[\"job\"]\n",
    "    print(f\"lex={r['lexical']:.3f}\")\n",
    "    print(f\"{job.title} @ {job.company}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72cdd41",
   "metadata": {},
   "source": [
    "## Combining Scores\n",
    "### APPROACH I - Reciprocal Rank Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a0a2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 10: RRF FUSION ===\n",
      "0.0325 | Staff Machine Learning Engineer - Community Support Engineering @ airbnb\n",
      "0.0325 | Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb\n",
      "0.0317 | Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "0.0312 | Senior Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "0.0282 | Staff Software Engineer, Data Warehouse Compute @ airbnb\n",
      "0.0280 | Senior Machine Learning Engineer, Stripe Assistant @ stripe\n",
      "0.0280 | Senior Solutions Engineer @ databricks\n",
      "0.0279 | Staff Software Engineer, Experimentation Data @ airbnb\n",
      "0.0279 | Director, Engineering - Databricks Mosaic AI @ databricks\n",
      "0.0277 | Senior Software Engineer - Fullstack (NYC) @ databricks\n"
     ]
    }
   ],
   "source": [
    "# RRF reciprocal rank fusion\n",
    "\n",
    "def rrf_fusion(sem_rank, lex_rank, k=60):\n",
    "    return 1/(k + sem_rank) + 1/(k + lex_rank)\n",
    "\n",
    "# rank separately\n",
    "sem_sorted = sorted(rows, key=lambda r: r[\"semantic\"], reverse=True)\n",
    "lex_sorted = sorted(rows, key=lambda r: r[\"lexical\"], reverse=True)\n",
    "\n",
    "sem_rank = {id(r): i+1 for i, r in enumerate(sem_sorted)}\n",
    "lex_rank = {id(r): i+1 for i, r in enumerate(lex_sorted)}\n",
    "\n",
    "rrf_scored = []\n",
    "for r in rows:\n",
    "    score = rrf_fusion(sem_rank[id(r)], lex_rank[id(r)])\n",
    "    rrf_scored.append((score, r))\n",
    "\n",
    "rrf_scored.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "print(\"\\n=== TOP 10: RRF FUSION ===\")\n",
    "for s, r in rrf_scored[:10]:\n",
    "    j = r[\"job\"]\n",
    "    print(f\"{s:.4f} | {j.title} @ {j.company}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c00ce97",
   "metadata": {},
   "source": [
    "### APPROACH II - Product of Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1981984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 10: PRODUCT OF EXPERTS ===\n",
      "-0.028 | sem=0.407 lex=0.407 | Staff Machine Learning Engineer, Listings and Host Tools Data and AI\n",
      "-0.029 | sem=0.401 lex=0.422 | Staff Machine Learning Engineer - Community Support Engineering\n",
      "-0.053 | sem=0.359 lex=0.369 | Staff Machine Learning Engineer, Communication & Connectivity\n",
      "-0.058 | sem=0.353 lex=0.356 | Senior Staff Machine Learning Engineer, Communication & Connectivity\n",
      "-0.215 | sem=0.239 lex=0.339 | Senior Machine Learning Engineer, Stripe Assistant\n",
      "-0.276 | sem=0.245 lex=0.206 | Staff Software Engineer, Experimentation Data\n",
      "-0.317 | sem=0.211 lex=0.268 | Senior Data Scientist - Inference, Global Markets\n",
      "-0.343 | sem=0.308 lex=0.129 | Senior Solutions Engineer\n",
      "-0.346 | sem=0.309 lex=0.128 | Director, Engineering - Databricks Mosaic AI\n",
      "-0.347 | sem=0.248 lex=0.161 | Staff Software Engineer, Data Warehouse Compute\n"
     ]
    }
   ],
   "source": [
    "# Product of Experts (PoE) — “semantic with lexical a-priori”\n",
    "\n",
    "sem_vals = np.array([r[\"semantic\"] for r in rows])\n",
    "lex_vals = np.array([r[\"lexical\"] for r in rows])\n",
    "\n",
    "mu_s, sd_s = sem_vals.mean(), sem_vals.std() + 1e-9\n",
    "mu_l, sd_l = lex_vals.mean(), lex_vals.std() + 1e-9\n",
    "\n",
    "def zsig(x, mu, sd):\n",
    "    return 1 / (1 + np.exp(-(x - mu)/sd))\n",
    "\n",
    "def poe_score(sem, lex, a=1.0, b=1.0, eps=1e-6):\n",
    "    ps = zsig(sem, mu_s, sd_s)\n",
    "    pl = zsig(lex, mu_l, sd_l)\n",
    "    return a*np.log(ps + eps) + b*np.log(pl + eps)\n",
    "\n",
    "poe_scored = []\n",
    "for r in rows:\n",
    "    s = poe_score(r[\"semantic\"], r[\"lexical\"], a=1.0, b=1.0)\n",
    "    poe_scored.append((s, r))\n",
    "\n",
    "poe_scored.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "print(\"\\n=== TOP 10: PRODUCT OF EXPERTS ===\")\n",
    "for s, r in poe_scored[:10]:\n",
    "    j = r[\"job\"]\n",
    "    print(f\"{s:.3f} | sem={r['semantic']:.3f} lex={r['lexical']:.3f} | {j.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92357e",
   "metadata": {},
   "source": [
    "## Extracting Job Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0125209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N = 10\n",
    "enriched = []\n",
    "\n",
    "for poe, r in poe_scored[:TOP_N]:\n",
    "    job = r[\"job\"]\n",
    "    sem = r[\"semantic\"]\n",
    "    lex = r[\"lexical\"]\n",
    "\n",
    "    # 1. check cache\n",
    "    full_text = store.load_job_detail(job.job_id)\n",
    "\n",
    "    # 2. fetch + extract if missing\n",
    "    if full_text is None:\n",
    "        print(f\"[enrich] fetching {job.job_id}\")\n",
    "        html = fetch_job_page(job.apply_url)\n",
    "        full_text = extract_job_text(html)\n",
    "        store.save_job_detail(job.job_id, full_text)\n",
    "\n",
    "    enriched.append({\n",
    "        \"poe\": poe,\n",
    "        \"semantic\": sem,\n",
    "        \"lexical\": lex,\n",
    "        \"job\": job,\n",
    "        \"full_text\": full_text,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0909518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.028 | sem=0.407 lex=0.407 | Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb\n",
      "-0.029 | sem=0.401 lex=0.422 | Staff Machine Learning Engineer - Community Support Engineering @ airbnb\n",
      "-0.053 | sem=0.359 lex=0.369 | Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "-0.058 | sem=0.353 lex=0.356 | Senior Staff Machine Learning Engineer, Communication & Connectivity @ airbnb\n",
      "-0.215 | sem=0.239 lex=0.339 | Senior Machine Learning Engineer, Stripe Assistant @ stripe\n",
      "-0.276 | sem=0.245 lex=0.206 | Staff Software Engineer, Experimentation Data @ airbnb\n",
      "-0.317 | sem=0.211 lex=0.268 | Senior Data Scientist - Inference, Global Markets @ airbnb\n",
      "-0.343 | sem=0.308 lex=0.129 | Senior Solutions Engineer @ databricks\n",
      "-0.346 | sem=0.309 lex=0.128 | Director, Engineering - Databricks Mosaic AI @ databricks\n",
      "-0.347 | sem=0.248 lex=0.161 | Staff Software Engineer, Data Warehouse Compute @ airbnb\n"
     ]
    }
   ],
   "source": [
    "for e in enriched:\n",
    "    j = e[\"job\"]\n",
    "    print(\n",
    "        f\"{e['poe']:+.3f} | \"\n",
    "        f\"sem={e['semantic']:.3f} \"\n",
    "        f\"lex={e['lexical']:.3f} | \"\n",
    "        f\"{j.title} @ {j.company}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bd947",
   "metadata": {},
   "source": [
    "## Generating Cover Letter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79ffd5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5253\n",
      "Manush Kalwari\n",
      "manushkalwari141@gmail.com | LinkedIn:manush-kalwari | GitHub:ManushKalwari | Portfolio Website\n",
      "Technologies\n",
      "Machine Learning & Generative AI: PyTorch, TensorFlow, HuggingFace, scikit-learn, LangChain, LangGraph, Optimizations (LoRA, GRPO,\n",
      "quantization, FlashAttention), Docker, CI/CD (GitHub Actions, GitLab), Comet ML, Weights & Biases\n",
      "Cloud: AWS (S3, SageMaker, Lambda, EC2), GCP (Vertex AI, BigQuery , Cloud Run, GKE, Composer, Dataflow)\n",
      "High Performance ML: CUDA, Sharding, multi-GPU training, profiling, distributed training\n",
      "Education\n",
      "Columbia University, MS in Electrical Engineering (Specialization in ML) Sept 2024 – Dec 2025 (Exp.)\n",
      "• Coursework: Advanced Deep Learning, Scaling LLM Systems, High-Performance ML, Generative AI, Mathematics of ML\n",
      "PROJECTS\n",
      "ScaleRAG - Multi-Moda\n"
     ]
    }
   ],
   "source": [
    "resume_text = parse_resume_pdf(\"../resume.pdf\")\n",
    "\n",
    "print(len(resume_text))\n",
    "print(resume_text[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46af42",
   "metadata": {},
   "source": [
    "### APPROACH I - GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eec3a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[generate 1/10] Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"../keys.env\")\n",
    "cover_letters = []\n",
    "\n",
    "for i, e in enumerate(enriched[:1], start=1):\n",
    "    job = e[\"job\"]\n",
    "    job_text = e[\"full_text\"]\n",
    "\n",
    "    print(f\"\\n[generate {i}/10] {job.title} @ {job.company}\")\n",
    "\n",
    "    cl = generate_cover_letter_gpt(\n",
    "        resume_text=resume_text,\n",
    "        job_text=job_text,\n",
    "        company=job.company,\n",
    "        role=job.title,\n",
    "    )\n",
    "\n",
    "    cover_letters.append({\n",
    "        \"job_id\": job.job_id,\n",
    "        \"company\": job.company,\n",
    "        \"title\": job.title,\n",
    "        \"poe\": e[\"poe\"],\n",
    "        \"cover_letter\": cl,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "887a316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb  |  PoE=-0.028\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Dear Airbnb Hiring Team,\n",
      "\n",
      "I am excited to apply for the Staff Machine Learning Engineer, Listings and Host Tools Data and AI role. As a Columbia University MS candidate specializing in ML, I have built and deployed end-to-end ML systems that span data pipelines, model development, and production-grade serving. My work focuses on delivering product-facing capabilities with strong observability, scalability, and close collaboration with cross-functional partners.\n",
      "\n",
      "In ScaleRAG, I designed a hierarchical multimodal retrieval framework for large corpora, integrating components such as FAISS indexing, vLLM, and PagedAttention. I built an end-to-end evaluation and benchmarking pipeline (including OpenAI GPT-4.1, LangChain, and multiprocessing) and deployed a real-time interface via FastAPI, Next.js, and GCP hosting. The project emphasizes latency, memory, and throughput trade-offs, with a reported 1.4× throughput improvement on single-GPU setups and an emphasis on grounding faithfulness and retrieval quality—capabilities directly translatable to product use cases in host and listing tools.\n",
      "\n",
      "My Resource-Efficient Model Optimization Pipeline demonstrates practical production-readiness under VRAM constraints: adapting DeepSeek and Phi-Mini for math reasoning on a single T4, employing LoRA and quantization, and benchmarking against FP runs. The multi-objective optimization approach improved GPU utilization to 97% and highlighted how to balance model quality with cost—an essential capability for sustaining scalable ML features in a marketplace setting.\n",
      "\n",
      "Additionally, I built a Real-Time AI Monitoring Platform featuring a containerized inference service (FastAPI, Docker Compose) with Prometheus + Grafana dashboards, Postgres logging, and secure API-key authentication. The modular observability layer reduces setup time for new endpoints by 50%, illustrating my ability to deliver maintainable, scalable ML infrastructure that supports fast iteration and product experimentation.\n",
      "\n",
      "I am eager to bring this blend of end-to-end ML engineering, optimization under constraints, and production-grade delivery to Airbnb’s Listings and Host Tools team—collaborating with data scientists and engineers to improve host and guest experiences through data-driven, scalable ML solutions. Thank you for considering my application; I welcome the opportunity to discuss how my background aligns with your needs.\n",
      "\n",
      "Sincerely,\n",
      "Manush Kalwari\n",
      "manushkalwari141@gmail.com\n"
     ]
    }
   ],
   "source": [
    "for c in cover_letters:\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"{c['title']} @ {c['company']}  |  PoE={c['poe']:.3f}\")\n",
    "    print(\"-\" * 100)\n",
    "    print(c[\"cover_letter\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f2f54",
   "metadata": {},
   "source": [
    "### APPROACH II - Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d56f811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[generate 1/10] Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb\n"
     ]
    }
   ],
   "source": [
    "my_llm = LocalLLM()\n",
    "cover_letters2 = []\n",
    "\n",
    "for i, e in enumerate(enriched[:1], start=1):\n",
    "    job = e[\"job\"]\n",
    "    job_text = e[\"full_text\"]\n",
    "\n",
    "    print(f\"\\n[generate {i}/10] {job.title} @ {job.company}\")\n",
    "\n",
    "    cl = generate_cover_letter_local(\n",
    "        resume_text=resume_text,\n",
    "        job_text=job_text,\n",
    "        company=job.company,\n",
    "        role=job.title,\n",
    "        llm=my_llm,\n",
    "    )\n",
    "\n",
    "    cover_letters2.append({\n",
    "        \"job_id\": job.job_id,\n",
    "        \"company\": job.company,\n",
    "        \"title\": job.title,\n",
    "        \"poe\": e[\"poe\"],\n",
    "        \"cover_letter\": cl,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdd2f7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Staff Machine Learning Engineer, Listings and Host Tools Data and AI @ airbnb  |  PoE=-0.028\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Diversity And Inclusion\n",
      "At Airbnb, we believe that diversity makes us better. Our mission is to bring people together through travel and hospitality. We strive to create a workplace culture that reflects this belief and values inclusion, equity, and belonging. We encourage all candidates to apply regardless of race, ethnicity, gender identity, sexual orientation, religion, disability status, veteran status, or any other characteristic protected by law.\n",
      "We are committed to providing equal employment opportunities to all individuals and do not discriminate based on race, color, national origin, age, sex, marital status, physical or mental disability, veteran status, gender identity, or sexual orientation. If you require reasonable accommodation during the application process due to a disability, please contact us via email at accommodations@airbnb.com.\n",
      "As part of our commitment to diversity and inclusion, we strongly encourage women, members of underrepresented racial and ethnic groups, LGBTQIA+, persons with disabilities, veterans, and others to apply for this position.\n",
      "Apply now! Please submit your resume along with a brief cover letter describing how your background and experiences match the job description. We look forward to hearing from you!\n",
      "Thank you for considering Airbnb. We appreciate your interest in joining our diverse community of travelers and hosts.\n"
     ]
    }
   ],
   "source": [
    "for c in cover_letters2:\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"{c['title']} @ {c['company']}  |  PoE={c['poe']:.3f}\")\n",
    "    print(\"-\" * 100)\n",
    "    print(c[\"cover_letter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3bb81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
